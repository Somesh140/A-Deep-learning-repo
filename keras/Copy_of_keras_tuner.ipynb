{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Somesh140/ANN/blob/main/keras/Copy_of_keras_tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Introduction to the Keras Tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/keras_tuner\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The Keras Tuner is a library that helps you pick the optimal set of hyperparameters for your TensorFlow program. The process of selecting the right set of hyperparameters for your machine learning (ML) application is called *hyperparameter tuning* or *hypertuning*.\n",
        "\n",
        "Hyperparameters are the variables that govern the training process and the topology of an ML model. These variables remain constant over the training process and directly impact the performance of your ML program. Hyperparameters are of two types:\n",
        "1. **Model hyperparameters** which influence model selection such as the number and width of hidden layers\n",
        "2. **Algorithm hyperparameters** which influence the speed and quality of the learning algorithm such as the learning rate for Stochastic Gradient Descent (SGD) and the number of nearest neighbors for a k Nearest Neighbors (KNN) classifier\n",
        "\n",
        "In this tutorial, you will use the Keras Tuner to perform hypertuning for an image classification application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g83Lwsy-Aq2_"
      },
      "source": [
        "Install and import the Keras Tuner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hpMLpbt9jcO6",
        "outputId": "15597f7e-2f6f-43e5-d5df-e948db8a0cd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 135 kB 30.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 61.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_leAIdFKAxAD"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReV_UXOgCZvx"
      },
      "source": [
        "## Download and prepare the dataset\n",
        "\n",
        "In this tutorial, you will use the Keras Tuner to find the best hyperparameters for a machine learning model that classifies images of clothing from the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HljH_ENLEdHa"
      },
      "source": [
        "Load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OHlHs9Wj_PUM",
        "outputId": "664f165a-3d3c-4872-f088-32e8ede3289d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_train"
      ],
      "metadata": {
        "id": "uvkQ_tGNn2OK",
        "outputId": "1f13aa29-0618-4e82-a1f2-f813561dbdd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhKy1AymOO3E",
        "outputId": "8d3b11fe-2342-41a1-9531-3a85868a17c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC39dj1PLILU",
        "outputId": "56c3f268-ba66-411e-cb6d-49a4dc30bcc0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img_train[0], cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "92ZjOiYopORo",
        "outputId": "481a1845-0de4-4532-b298-43f00558152d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAKRElEQVR4nO3dy2/N3R/F8d3HpbSSaqXu1bgNOqiIqNAhISoxMDc1MiZh4C8wNxFMS4iRSCUGNKQuIQYI4hZxJ6rUtTyDX36/Ub9rPTkn/VnN834Nu7JPz6UrJ+kne++G379/FwB5/vrTTwDA+CgnEIpyAqEoJxCKcgKhppqcf+UCE69hvB/yzQmEopxAKMoJhKKcQCjKCYSinEAoygmEopxAKMoJhKKcQCjKCYSinEAoygmEopxAKMoJhKKcQCjKCYSinEAoygmEopxAKMoJhKKcQCh3NCb+z9zFUg0N456i+I+NjIzIfHBwsDLr6+ur63e71zY2NlaZTZ36Z/9U67nwq9bPjG9OIBTlBEJRTiAU5QRCUU4gFOUEQlFOIBRzzjC/fv2S+ZQpU2T+4MEDmR8+fFjmM2fOrMyam5vl2hkzZsh83bp1Mq9nlunmkO59devreW5qfltK9WfKNycQinICoSgnEIpyAqEoJxCKcgKhKCcQijlnmFpnYv91/vx5mZ87d07mHR0dldm3b9/k2tHRUZkPDAzIfNeuXZXZvHnz5Fq3Z9K9b86nT58qs7/+0t9xTU1NNf1OvjmBUJQTCEU5gVCUEwhFOYFQlBMIRTmBUMw5w0yfPr2u9VevXpX548ePZa72Pbo9kVu2bJH5jRs3ZL53797KbO3atXJtd3e3zLu6umR+5coVmav3tbe3V67dsGGDzFtaWsb9Od+cQCjKCYSinEAoygmEopxAKMoJhGowRwLWfu8ZKqn33G19clu+1DiilFI+fPgg82nTplVmbmuU09PTI/MVK1ZUZm7E5I62fPnypczd0ZfqWM8TJ07Itbt375b5xo0bx/3Q+eYEQlFOIBTlBEJRTiAU5QRCUU4gFOUEQjHnrIGbqdXDzTnXr18vc7clzFGvzR0v2djYWNfvVlcIuvdlzZo1Ml+5cqXM3Ws7e/ZsZfbw4UO59vnz5zIvpTDnBCYTygmEopxAKMoJhKKcQCjKCYSinEAojsasgZu5TaTW1laZv3jxQuYzZ86Uubrm78ePH3KtuiavFD3HLKWUL1++VGbuPR8cHJT5pUuXZO5m169evarMtm7dKtfWim9OIBTlBEJRTiAU5QRCUU4gFOUEQlFOIBRzzklmdHRU5mNjYzJ31/ipOej8+fPl2jlz5sjc7TVV5+K6OaR73WqG6n53KXq/57Nnz+TaWvHNCYSinEAoygmEopxAKMoJhKKcQCjKCYRizlkDN3Nzs0Q1M3N7It0ZqO7sWHfP5ffv32t+7ObmZpkPDw/LXM1J3XxXPe9SSpk1a5bMP378KPPu7u7K7PPnz3LttWvXZL527dpxf843JxCKcgKhKCcQinICoSgnEIpyAqEYpdTAHdPoti+pUUp/f79c646+bG9vl7nbOqWemxsZPH36VObTpk2TuTqWc+pU/afqju10r/vt27cy3717d2V28+ZNufbnz58yr8I3JxCKcgKhKCcQinICoSgnEIpyAqEoJxCqwWx/0nuj/qXc3MrN5JShoSGZb9u2Tebuir96ZrD1XvHX1tYmc/W+ujmmm8G6qxMd9dr27Nkj1+7cudM9/LiDc745gVCUEwhFOYFQlBMIRTmBUJQTCEU5gVATup9TzVDrvarOHU+p9g66696ceuaYTl9fn8zdEY9uzumOkFTcXlE3//369avM3bGdivtM3Gfu/h5v3bpVmbW0tMi1teKbEwhFOYFQlBMIRTmBUJQTCEU5gVCUEwhV18Cunr2BEzkrnGgXLlyQ+cmTJ2U+ODhYmTU1Ncm16pq8UvTZr6X4M3fV5+Kem/t7cM9NzUHd83bXDzpu/qse/9SpU3Lt9u3ba3pOfHMCoSgnEIpyAqEoJxCKcgKhKCcQinICoWLPrX3//r3Mnz9/LvN79+7VvNbNrdRjl1JKY2OjzNVeVben0d0zuXDhQpm7eZ46H9bdYele9+joqMx7e3srs5GREbn24sWLMnf7Od2eTPW+zZ8/X669c+eOzAvn1gKTC+UEQlFOIBTlBEJRTiAU5QRC1TVKuXz5snzwAwcOVGZv3ryRaz98+CBz969xNa6YPXu2XKu2upXiRwJupKDec3e0ZVdXl8z7+/tl3tPTI/OPHz9WZu4zefz4scydpUuXVmbu+kF3ZKjbUuY+U3XF4PDwsFzrxl+FUQowuVBOIBTlBEJRTiAU5QRCUU4gFOUEQsk559jYmJxzbtiwQT642ppV75Vt9RyF6K6qc7PGeqm52Lt37+TaY8eOyXxgYEDmhw4dkvmCBQsqsxkzZsi1ak5ZSinLly+X+f379ysz976oKx9L8Z+5mu+WorfSubn4kydPZF6YcwKTC+UEQlFOIBTlBEJRTiAU5QRCUU4glJxzHjlyRM459+3bJx982bJllZnaH1eKPwrRXSenuJmX25+3ePFimS9atEjmai+r2odaSikvX76U+enTp2WurtkrpZRHjx5VZu4zu379el25ukKwnuNGS/FHgjqqJ+6xh4aGZN7R0cGcE5hMKCcQinICoSgnEIpyAqEoJxCKcgKh5KbKuXPnysVu3qdmlW5utWTJkpofuxS9/87t3Wtra5N5Z2enzN1zU/si3Z5Jt3dwx44dMu/u7pa5OnvW7al0n6k7L1jtyXSv212d6GaRbv+wmnOas5/tlZEdHR3jPye5CsAfQzmBUJQTCEU5gVCUEwhFOYFQcpTiRiXu389V/yIuxW8/clcEun/Lt7e315SV4reUue1qbr3atuWuulPbqkopZc6cOTK/ffu2zNVVem681draKnO3XU19Lu4oVXc0plvvrulTW/VaWlrk2ps3b8p806ZN4/6cb04gFOUEQlFOIBTlBEJRTiAU5QRCUU4glBz+rF69Wi5225OOHj1amS1cuFCuddfFua1Val7otg+5mZfajlaKn3Oq5+7WNjSMe4ri/zQ1NclcXfFXip5du21b7rm72XQ9WwzdY7vcbTlTc1R1nGgppcybN0/mVfjmBEJRTiAU5QRCUU4gFOUEQlFOIBTlBELJKwBLKfrMP+PMmTOV2cGDB+Xa169fy9ztyVRzLbcP1V0n5/Zzuj2Xah7ojll0c043a3QzXpW7x3bP3VHr3TGtjptNu78JtZ9z1apVcu3x48dlXkrhCkBgMqGcQCjKCYSinEAoygmEopxAKMoJhJJzzl+/fsnBlZsN1eP8+fMy379/v8xfvXpVmQ0PD8u1bl7n5phupqbOUHW/28373By0nrOI1Zm2pfj3pR5uv6Xbx+pm15s3b5Z5V1dXZdbb2yvX/gPMOYHJhHICoSgnEIpyAqEoJxCKcgKhKCcQakL3c6a6e/euzN3doO4eymfPnsm8s7OzMnPzPHeeLyYl5pzAZEI5gVCUEwhFOYFQlBMIRTmBUP/KUQoQhlEKMJlQTiAU5QRCUU4gFOUEQlFOIBTlBEJRTiAU5QRCUU4gFOUEQlFOIBTlBEJRTiAU5QRCVd9F9x/6PjkAE4ZvTiAU5QRCUU4gFOUEQlFOIBTlBEL9DRgW8qPu1lMTAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train[0]"
      ],
      "metadata": {
        "id": "Kn5tVVD0oWih",
        "outputId": "3a6030a0-026a-419c-91b7-d387d8f53153",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
              "          0,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
              "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
              "         72,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
              "        172,  66],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
              "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
              "        229,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
              "        173,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
              "        202,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
              "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
              "        209,  52],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
              "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
              "        167,  56],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "         92,   0],\n",
              "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
              "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
              "         77,   0],\n",
              "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
              "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
              "        159,   0],\n",
              "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
              "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
              "        215,   0],\n",
              "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
              "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
              "        246,   0],\n",
              "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
              "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
              "        225,   0],\n",
              "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
              "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
              "        229,  29],\n",
              "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
              "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
              "        230,  67],\n",
              "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
              "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
              "        206, 115],\n",
              "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
              "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
              "        210,  92],\n",
              "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
              "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
              "        170,   0],\n",
              "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
              "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bLVhXs3xrUD0"
      },
      "outputs": [],
      "source": [
        "# Normalize pixel values between 0 and 1\n",
        "img_train = img_train.astype('float32') / 255.0\n",
        "img_test = img_test.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train[0]"
      ],
      "metadata": {
        "id": "MODjxJENtFBI",
        "outputId": "d6545571-3b98-4084-c5b3-2b1c5d0946d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.05098039, 0.28627452, 0.        , 0.        , 0.00392157,\n",
              "        0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.00392157, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.        , 0.14117648,\n",
              "        0.53333336, 0.49803922, 0.24313726, 0.21176471, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568628,\n",
              "        0.        , 0.        , 0.01176471],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
              "        0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
              "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04705882, 0.03921569, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.60784316,\n",
              "        0.9254902 , 0.8117647 , 0.69803923, 0.41960785, 0.6117647 ,\n",
              "        0.6313726 , 0.42745098, 0.2509804 , 0.09019608, 0.3019608 ,\n",
              "        0.50980395, 0.28235295, 0.05882353],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.27058825, 0.8117647 ,\n",
              "        0.8745098 , 0.85490197, 0.84705883, 0.84705883, 0.6392157 ,\n",
              "        0.49803922, 0.4745098 , 0.47843137, 0.57254905, 0.5529412 ,\n",
              "        0.34509805, 0.6745098 , 0.25882354],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.        , 0.78431374, 0.9098039 ,\n",
              "        0.9098039 , 0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 ,\n",
              "        0.84313726, 0.8352941 , 0.6431373 , 0.49803922, 0.48235294,\n",
              "        0.76862746, 0.8980392 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.7176471 , 0.88235295,\n",
              "        0.84705883, 0.8745098 , 0.89411765, 0.92156863, 0.8901961 ,\n",
              "        0.8784314 , 0.87058824, 0.8784314 , 0.8666667 , 0.8745098 ,\n",
              "        0.9607843 , 0.6784314 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
              "        0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
              "        0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
              "        0.9529412 , 0.7921569 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.01176471, 0.        , 0.04705882, 0.85882354, 0.8627451 ,\n",
              "        0.83137256, 0.85490197, 0.7529412 , 0.6627451 , 0.8901961 ,\n",
              "        0.8156863 , 0.85490197, 0.8784314 , 0.83137256, 0.8862745 ,\n",
              "        0.77254903, 0.81960785, 0.20392157],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.        , 0.3882353 , 0.95686275, 0.87058824,\n",
              "        0.8627451 , 0.85490197, 0.79607844, 0.7764706 , 0.8666667 ,\n",
              "        0.84313726, 0.8352941 , 0.87058824, 0.8627451 , 0.9607843 ,\n",
              "        0.46666667, 0.654902  , 0.21960784],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
              "        0.        , 0.        , 0.21568628, 0.9254902 , 0.89411765,\n",
              "        0.9019608 , 0.89411765, 0.9411765 , 0.9098039 , 0.8352941 ,\n",
              "        0.85490197, 0.8745098 , 0.91764706, 0.8509804 , 0.8509804 ,\n",
              "        0.81960785, 0.36078432, 0.        ],\n",
              "       [0.        , 0.        , 0.00392157, 0.01568628, 0.02352941,\n",
              "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.92941177, 0.8862745 , 0.8509804 ,\n",
              "        0.8745098 , 0.87058824, 0.85882354, 0.87058824, 0.8666667 ,\n",
              "        0.84705883, 0.8745098 , 0.8980392 , 0.84313726, 0.85490197,\n",
              "        1.        , 0.3019608 , 0.        ],\n",
              "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
              "        0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
              "        0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
              "        0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
              "        0.95686275, 0.62352943, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
              "        0.17254902, 0.32156864, 0.41960785, 0.7411765 , 0.89411765,\n",
              "        0.8627451 , 0.87058824, 0.8509804 , 0.8862745 , 0.78431374,\n",
              "        0.8039216 , 0.827451  , 0.9019608 , 0.8784314 , 0.91764706,\n",
              "        0.6901961 , 0.7372549 , 0.98039216, 0.972549  , 0.9137255 ,\n",
              "        0.93333334, 0.84313726, 0.        ],\n",
              "       [0.        , 0.22352941, 0.73333335, 0.8156863 , 0.8784314 ,\n",
              "        0.8666667 , 0.8784314 , 0.8156863 , 0.8       , 0.8392157 ,\n",
              "        0.8156863 , 0.81960785, 0.78431374, 0.62352943, 0.9607843 ,\n",
              "        0.75686276, 0.80784315, 0.8745098 , 1.        , 1.        ,\n",
              "        0.8666667 , 0.91764706, 0.8666667 , 0.827451  , 0.8627451 ,\n",
              "        0.9098039 , 0.9647059 , 0.        ],\n",
              "       [0.01176471, 0.7921569 , 0.89411765, 0.8784314 , 0.8666667 ,\n",
              "        0.827451  , 0.827451  , 0.8392157 , 0.8039216 , 0.8039216 ,\n",
              "        0.8039216 , 0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 ,\n",
              "        1.        , 0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 ,\n",
              "        0.7490196 , 0.8235294 , 0.8       , 0.81960785, 0.87058824,\n",
              "        0.89411765, 0.88235295, 0.        ],\n",
              "       [0.38431373, 0.9137255 , 0.7764706 , 0.8235294 , 0.87058824,\n",
              "        0.8980392 , 0.8980392 , 0.91764706, 0.9764706 , 0.8627451 ,\n",
              "        0.7607843 , 0.84313726, 0.8509804 , 0.94509804, 0.25490198,\n",
              "        0.28627452, 0.41568628, 0.45882353, 0.65882355, 0.85882354,\n",
              "        0.8666667 , 0.84313726, 0.8509804 , 0.8745098 , 0.8745098 ,\n",
              "        0.8784314 , 0.8980392 , 0.11372549],\n",
              "       [0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
              "        0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
              "        0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
              "        0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
              "        0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
              "        0.8666667 , 0.9019608 , 0.2627451 ],\n",
              "       [0.1882353 , 0.79607844, 0.7176471 , 0.7607843 , 0.8352941 ,\n",
              "        0.77254903, 0.7254902 , 0.74509805, 0.7607843 , 0.7529412 ,\n",
              "        0.7921569 , 0.8392157 , 0.85882354, 0.8666667 , 0.8627451 ,\n",
              "        0.9254902 , 0.88235295, 0.84705883, 0.78039217, 0.80784315,\n",
              "        0.7294118 , 0.70980394, 0.69411767, 0.6745098 , 0.70980394,\n",
              "        0.8039216 , 0.80784315, 0.4509804 ],\n",
              "       [0.        , 0.47843137, 0.85882354, 0.75686276, 0.7019608 ,\n",
              "        0.67058825, 0.7176471 , 0.76862746, 0.8       , 0.8235294 ,\n",
              "        0.8352941 , 0.8117647 , 0.827451  , 0.8235294 , 0.78431374,\n",
              "        0.76862746, 0.7607843 , 0.7490196 , 0.7647059 , 0.7490196 ,\n",
              "        0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 , 0.654902  ,\n",
              "        0.69411767, 0.8235294 , 0.36078432],\n",
              "       [0.        , 0.        , 0.2901961 , 0.7411765 , 0.83137256,\n",
              "        0.7490196 , 0.6862745 , 0.6745098 , 0.6862745 , 0.70980394,\n",
              "        0.7254902 , 0.7372549 , 0.7411765 , 0.7372549 , 0.75686276,\n",
              "        0.7764706 , 0.8       , 0.81960785, 0.8235294 , 0.8235294 ,\n",
              "        0.827451  , 0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 ,\n",
              "        0.84705883, 0.6666667 , 0.        ],\n",
              "       [0.00784314, 0.        , 0.        , 0.        , 0.25882354,\n",
              "        0.78431374, 0.87058824, 0.92941177, 0.9372549 , 0.9490196 ,\n",
              "        0.9647059 , 0.9529412 , 0.95686275, 0.8666667 , 0.8627451 ,\n",
              "        0.75686276, 0.7490196 , 0.7019608 , 0.7137255 , 0.7137255 ,\n",
              "        0.70980394, 0.6901961 , 0.6509804 , 0.65882355, 0.3882353 ,\n",
              "        0.22745098, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
              "        0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5YEL2H2Ax3e"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "When you build a model for hypertuning, you also define the hyperparameter search space in addition to the model architecture. The model you set up for hypertuning is called a *hypermodel*.\n",
        "\n",
        "You can define a hypermodel through two approaches:\n",
        "\n",
        "* By using a model builder function\n",
        "* By subclassing the `HyperModel` class of the Keras Tuner API\n",
        "\n",
        "You can also use two pre-defined [HyperModel](https://keras.io/api/keras_tuner/hypermodels/) classes - [HyperXception](https://keras.io/api/keras_tuner/hypermodels/hyper_xception/) and [HyperResNet](https://keras.io/api/keras_tuner/hypermodels/hyper_resnet/) for computer vision applications.\n",
        "\n",
        "In this tutorial, you use a model builder function to define the image classification model. The model builder function returns a compiled model and uses hyperparameters you define inline to hypertune the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZQKodC-jtsva"
      },
      "outputs": [],
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  #input layers\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(10))#output layer\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1VYw4q3x0b"
      },
      "source": [
        "## Instantiate the tuner and perform hypertuning\n",
        "\n",
        "Instantiate the tuner to perform the hypertuning. The Keras Tuner has four tuners available - `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`. In this tutorial, you use the [Hyperband](https://arxiv.org/pdf/1603.06560.pdf) tuner.\n",
        "\n",
        "To instantiate the Hyperband tuner, you must specify the hypermodel, the `objective` to optimize and the maximum number of epochs to train (`max_epochs`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oichQFly6Y46"
      },
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaIhhdKf9VtI"
      },
      "source": [
        "The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing 1 + log<sub>`factor`</sub>(`max_epochs`) and rounding it up to the nearest integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwhBdXx0Ekj8"
      },
      "source": [
        "Create a callback to stop training early after reaching a certain value for the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WT9IkS9NEjLc"
      },
      "outputs": [],
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKghEo15Tduy"
      },
      "source": [
        "Run the hyperparameter search. The arguments for the search method are the same as those used for `tf.keras.model.fit` in addition to the callback above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dSBQcTHF9cKt",
        "outputId": "cc885053-e999-4ba2-c806-149da050b6fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 42s]\n",
            "val_accuracy: 0.8882499933242798\n",
            "\n",
            "Best val_accuracy So Far: 0.890999972820282\n",
            "Total elapsed time: 00h 10m 12s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 416 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lak_ylf88xBv"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Find the optimal number of epochs to train the model with the hyperparameters obtained from the search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "McO82AXOuxXh",
        "outputId": "2313d044-2b1f-44bb-b8f6-24976efdb78e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4968 - accuracy: 0.8235 - val_loss: 0.4569 - val_accuracy: 0.8266\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3702 - accuracy: 0.8655 - val_loss: 0.3588 - val_accuracy: 0.8702\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3313 - accuracy: 0.8777 - val_loss: 0.3624 - val_accuracy: 0.8685\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3060 - accuracy: 0.8862 - val_loss: 0.3323 - val_accuracy: 0.8783\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2860 - accuracy: 0.8937 - val_loss: 0.3512 - val_accuracy: 0.8788\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2709 - accuracy: 0.8990 - val_loss: 0.3395 - val_accuracy: 0.8786\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2580 - accuracy: 0.9042 - val_loss: 0.3200 - val_accuracy: 0.8837\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2467 - accuracy: 0.9084 - val_loss: 0.3174 - val_accuracy: 0.8877\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2346 - accuracy: 0.9133 - val_loss: 0.3328 - val_accuracy: 0.8840\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2237 - accuracy: 0.9158 - val_loss: 0.3299 - val_accuracy: 0.8828\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2169 - accuracy: 0.9182 - val_loss: 0.3095 - val_accuracy: 0.8932\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2110 - accuracy: 0.9202 - val_loss: 0.3183 - val_accuracy: 0.8911\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1988 - accuracy: 0.9255 - val_loss: 0.3212 - val_accuracy: 0.8932\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1913 - accuracy: 0.9287 - val_loss: 0.3302 - val_accuracy: 0.8925\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1856 - accuracy: 0.9294 - val_loss: 0.3456 - val_accuracy: 0.8862\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1813 - accuracy: 0.9320 - val_loss: 0.3426 - val_accuracy: 0.8928\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1728 - accuracy: 0.9351 - val_loss: 0.3699 - val_accuracy: 0.8888\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1699 - accuracy: 0.9364 - val_loss: 0.3533 - val_accuracy: 0.8922\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1636 - accuracy: 0.9374 - val_loss: 0.3502 - val_accuracy: 0.8935\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1588 - accuracy: 0.9395 - val_loss: 0.3753 - val_accuracy: 0.8870\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1520 - accuracy: 0.9425 - val_loss: 0.3535 - val_accuracy: 0.8917\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1480 - accuracy: 0.9450 - val_loss: 0.3741 - val_accuracy: 0.8906\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1443 - accuracy: 0.9449 - val_loss: 0.3710 - val_accuracy: 0.8919\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1399 - accuracy: 0.9477 - val_loss: 0.3797 - val_accuracy: 0.8892\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1351 - accuracy: 0.9491 - val_loss: 0.3729 - val_accuracy: 0.8967\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1318 - accuracy: 0.9500 - val_loss: 0.4123 - val_accuracy: 0.8878\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1294 - accuracy: 0.9517 - val_loss: 0.3915 - val_accuracy: 0.8898\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1265 - accuracy: 0.9523 - val_loss: 0.4126 - val_accuracy: 0.8934\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1212 - accuracy: 0.9541 - val_loss: 0.3827 - val_accuracy: 0.8997\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1162 - accuracy: 0.9555 - val_loss: 0.4383 - val_accuracy: 0.8899\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1159 - accuracy: 0.9564 - val_loss: 0.4305 - val_accuracy: 0.8922\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1117 - accuracy: 0.9584 - val_loss: 0.4035 - val_accuracy: 0.8959\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1093 - accuracy: 0.9583 - val_loss: 0.4528 - val_accuracy: 0.8867\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1058 - accuracy: 0.9599 - val_loss: 0.4675 - val_accuracy: 0.8890\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1024 - accuracy: 0.9619 - val_loss: 0.4349 - val_accuracy: 0.8960\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1024 - accuracy: 0.9620 - val_loss: 0.4799 - val_accuracy: 0.8892\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0995 - accuracy: 0.9622 - val_loss: 0.4402 - val_accuracy: 0.8951\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0963 - accuracy: 0.9638 - val_loss: 0.4845 - val_accuracy: 0.8914\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0941 - accuracy: 0.9650 - val_loss: 0.4476 - val_accuracy: 0.8948\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0920 - accuracy: 0.9659 - val_loss: 0.4559 - val_accuracy: 0.8938\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0910 - accuracy: 0.9648 - val_loss: 0.4813 - val_accuracy: 0.8936\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0880 - accuracy: 0.9672 - val_loss: 0.4716 - val_accuracy: 0.8939\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0871 - accuracy: 0.9676 - val_loss: 0.4943 - val_accuracy: 0.8926\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0834 - accuracy: 0.9694 - val_loss: 0.5150 - val_accuracy: 0.8947\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0828 - accuracy: 0.9683 - val_loss: 0.4865 - val_accuracy: 0.8958\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0831 - accuracy: 0.9694 - val_loss: 0.5201 - val_accuracy: 0.8933\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0780 - accuracy: 0.9707 - val_loss: 0.5428 - val_accuracy: 0.8936\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0805 - accuracy: 0.9699 - val_loss: 0.5354 - val_accuracy: 0.8920\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0755 - accuracy: 0.9723 - val_loss: 0.4993 - val_accuracy: 0.8960\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0753 - accuracy: 0.9714 - val_loss: 0.5144 - val_accuracy: 0.8953\n",
            "Best epoch: 29\n"
          ]
        }
      ],
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOTSirSTI3Gp"
      },
      "source": [
        "Re-instantiate the hypermodel and train it with the optimal number of epochs from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NoiPUEHmMhCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2c8e43-9a9c-4946-b628-8d7891e782c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4966 - accuracy: 0.8238 - val_loss: 0.4531 - val_accuracy: 0.8431\n",
            "Epoch 2/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3721 - accuracy: 0.8640 - val_loss: 0.3778 - val_accuracy: 0.8628\n",
            "Epoch 3/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3327 - accuracy: 0.8775 - val_loss: 0.3514 - val_accuracy: 0.8711\n",
            "Epoch 4/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3038 - accuracy: 0.8887 - val_loss: 0.3220 - val_accuracy: 0.8848\n",
            "Epoch 5/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2865 - accuracy: 0.8923 - val_loss: 0.3185 - val_accuracy: 0.8867\n",
            "Epoch 6/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2705 - accuracy: 0.9003 - val_loss: 0.3231 - val_accuracy: 0.8829\n",
            "Epoch 7/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2562 - accuracy: 0.9036 - val_loss: 0.3307 - val_accuracy: 0.8789\n",
            "Epoch 8/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2455 - accuracy: 0.9079 - val_loss: 0.3490 - val_accuracy: 0.8752\n",
            "Epoch 9/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2353 - accuracy: 0.9110 - val_loss: 0.3213 - val_accuracy: 0.8879\n",
            "Epoch 10/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2245 - accuracy: 0.9148 - val_loss: 0.3227 - val_accuracy: 0.8879\n",
            "Epoch 11/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2172 - accuracy: 0.9175 - val_loss: 0.3124 - val_accuracy: 0.8930\n",
            "Epoch 12/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2080 - accuracy: 0.9205 - val_loss: 0.3264 - val_accuracy: 0.8881\n",
            "Epoch 13/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1998 - accuracy: 0.9249 - val_loss: 0.3187 - val_accuracy: 0.8932\n",
            "Epoch 14/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1935 - accuracy: 0.9266 - val_loss: 0.3323 - val_accuracy: 0.8922\n",
            "Epoch 15/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1829 - accuracy: 0.9310 - val_loss: 0.3282 - val_accuracy: 0.8922\n",
            "Epoch 16/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1808 - accuracy: 0.9311 - val_loss: 0.3446 - val_accuracy: 0.8921\n",
            "Epoch 17/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1723 - accuracy: 0.9348 - val_loss: 0.3369 - val_accuracy: 0.8933\n",
            "Epoch 18/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1668 - accuracy: 0.9370 - val_loss: 0.3542 - val_accuracy: 0.8873\n",
            "Epoch 19/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1613 - accuracy: 0.9389 - val_loss: 0.3471 - val_accuracy: 0.8900\n",
            "Epoch 20/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1599 - accuracy: 0.9402 - val_loss: 0.3503 - val_accuracy: 0.8955\n",
            "Epoch 21/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1526 - accuracy: 0.9419 - val_loss: 0.3562 - val_accuracy: 0.8923\n",
            "Epoch 22/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1476 - accuracy: 0.9445 - val_loss: 0.3561 - val_accuracy: 0.8953\n",
            "Epoch 23/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1445 - accuracy: 0.9451 - val_loss: 0.3562 - val_accuracy: 0.8937\n",
            "Epoch 24/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1400 - accuracy: 0.9471 - val_loss: 0.3527 - val_accuracy: 0.8953\n",
            "Epoch 25/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1362 - accuracy: 0.9487 - val_loss: 0.4017 - val_accuracy: 0.8901\n",
            "Epoch 26/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1312 - accuracy: 0.9513 - val_loss: 0.3925 - val_accuracy: 0.8951\n",
            "Epoch 27/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1287 - accuracy: 0.9518 - val_loss: 0.4088 - val_accuracy: 0.8913\n",
            "Epoch 28/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1249 - accuracy: 0.9530 - val_loss: 0.3903 - val_accuracy: 0.8936\n",
            "Epoch 29/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1212 - accuracy: 0.9545 - val_loss: 0.3951 - val_accuracy: 0.8923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce387f89d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqU5ZVAaag2v"
      },
      "source": [
        "To finish this tutorial, evaluate the hypermodel on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9E0BTp9Ealjb",
        "outputId": "1f9e30f8-68a8-4b30-9d9a-a696276e043c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.8886\n",
            "[test loss, test accuracy]: [0.5987936854362488, 0.8885999917984009]\n"
          ]
        }
      ],
      "source": [
        "eval_result = model.evaluate(img_test, label_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQRpPHZsz-eC"
      },
      "source": [
        "The `my_dir/intro_to_kt` directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. To disable this behavior, pass an additional `overwrite=True` argument while instantiating the tuner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKwLOzKpFGAj"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned how to use the Keras Tuner to tune hyperparameters for a model. To learn more about the Keras Tuner, check out these additional resources:\n",
        "\n",
        "* [Keras Tuner on the TensorFlow blog](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n",
        "* [Keras Tuner website](https://keras-team.github.io/keras-tuner/)\n",
        "\n",
        "Also check out the [HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) in TensorBoard to interactively tune your model hyperparameters."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}